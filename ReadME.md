# LangGraph-Tutorials ğŸš€

This repository contains LangGraph workflow examples using both **OpenAI** and **Google Gemini (Generative AI)**. It includes everything from basic prompt chaining to an advanced chatbot with a Streamlit interface.

---

## ğŸ“ Step 1: Create `.env` File

```env
OPENAI_API_KEY=your-openai-api-key
GEMINI_API_KEY=your-google-gemini-api-key
```

```python
from dotenv import load_dotenv
load_dotenv()
```

---

## ğŸ Step 2: Set Up Conda Environment

```bash
conda create --name LangGraph-Tutorials python=3.13
conda activate LangGraph-Tutorials
```

---

## ğŸ“¦ Step 3: Install Dependencies

```bash
pip install langgraph langchain langchain_openai python-dotenv streamlit langchain-google-genai
```

If you're using **Google Gemini**:

```bash
pip install google-generativeai
```

â˜ï¸ **(Optional) Install Google Cloud SDK (for ADC)**  
Only required if you're using Gemini via Google Cloud Console instead of API Key:

```bash
curl https://sdk.cloud.google.com | bash
exec -l $SHELL
gcloud auth application-default login
```

---

## ğŸ§  Step 4: Sample Code for OpenAI & Gemini (LangChain + SDK)

### ğŸŸ¦ OpenAI Example (LangChain)

```python
from langchain_openai import ChatOpenAI
import os
from dotenv import load_dotenv

load_dotenv()
llm = ChatOpenAI(model="gpt-4", api_key=os.getenv("OPENAI_API_KEY"))
print(llm.invoke("Tell me a joke.").content)
```

### ğŸŸ¨ Google Gemini Example (LangChain)

```python
from langchain_google_genai import ChatGoogleGenerativeAI
import os
from dotenv import load_dotenv

load_dotenv()
llm = ChatGoogleGenerativeAI(
    model="gemini-pro",
    google_api_key=os.getenv("GEMINI_API_KEY")
)
print(llm.invoke("Define AI in one line.").content)
```

### ğŸŸ¨ Google Gemini Example (Native SDK)

```python
import google.generativeai as genai
import os
from dotenv import load_dotenv

load_dotenv()
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

model = genai.GenerativeModel("gemini-pro")
response = model.generate_content("Define AI in one line.")
print(response.text)
```

---

## ğŸ’¬ Step 5: Run the Streamlit Chatbot App

```bash
cd Workflows/06_AdvancedChatbot/app
streamlit run streamlit_frontend.py
```

---

## ğŸŒ´ Folder Structure

```
.
â”œâ”€â”€ README.md
â””â”€â”€ Workflows
    â”œâ”€â”€ 01_PromptChaining
    â”‚   â””â”€â”€ main.ipynb
    â”œâ”€â”€ 02_Sequential_Workflows
    â”‚   â”œâ”€â”€ BMICalculator
    â”‚   â”‚   â””â”€â”€ main.ipynb
    â”‚   â””â”€â”€ SimpleLLM
    â”‚       â””â”€â”€ main.ipynb
    â”œâ”€â”€ 03_Parallel_Workflow
    â”‚   â”œâ”€â”€ BatsmanPerformance
    â”‚   â”‚   â””â”€â”€ main.ipynb
    â”‚   â””â”€â”€ UPSCEssay
    â”‚       â”œâ”€â”€ gemini.ipynb
    â”‚       â””â”€â”€ openai.ipynb
    â”œâ”€â”€ 04_Conditional_Workflows
    â”‚   â”œâ”€â”€ LLM_Based_Gemini.ipynb
    â”‚   â”œâ”€â”€ LLM_Based_OpenAI.ipynb
    â”‚   â””â”€â”€ Quadratic_Equation.ipynb
    â”œâ”€â”€ 05_Iteratice_Workflows
    â”‚   â”œâ”€â”€ X_Post_Generator_Gemini.ipynb
    â”‚   â””â”€â”€ X_Post_Generator_OpenAI.ipynb
    â”œâ”€â”€ 06_AdvancedChatbot
    â”‚   â”œâ”€â”€ app
    â”‚   â”‚   â”œâ”€â”€ langgraph_backend.py
    â”‚   â”‚   â””â”€â”€ streamlit_frontend.py
    â”‚   â”œâ”€â”€ X_Post_Generator_Gemini.ipynb
    â”‚   â””â”€â”€ X_Post_Generator_OpenAI.ipynb
    â””â”€â”€ 07_Persistance
        â”œâ”€â”€ Persistence_Gemini.ipynb
        â””â”€â”€ Persistence_OpenAI.ipynb
```

---

## ğŸ§  Tips

- Use `.env` to securely manage API keys
- Easily switch between OpenAI and Gemini in your code
- Follow LangGraph docs to build custom multi-step workflows

---

Happy Building! âš™ï¸âœ¨
