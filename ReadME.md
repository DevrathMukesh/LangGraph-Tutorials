<!-- ðŸ“ Step 1: Create .env File -->
GEMINI_API_KEY=your_actual_api_key_here

<!-- ðŸ Step 2: Create a New Conda Environment -->
conda create --name LangGraph-Tutorials python=3.13
conda activate LangGraph-Tutorials

<!-- ðŸ“¦ Step 3: Install Required Libraries -->
pip install langgraph langchain langchain_openai python-dotenv streamlit

<!-- If you're using Gemini (Google Generative AI), also install: -->
pip install google-generativeai

<!-- ðŸ’¬ Step 4: Run the Streamlit Chatbot App -->
cd Workflows/06_AdvancedChatbot/app
streamlit run streamlit_frontend.py



<!-- ðŸŒ´: File Tree Overview -->
.
â”œâ”€â”€ ReadME.md
â””â”€â”€ Workflows
    â”œâ”€â”€ 01_PromptChaining
    â”‚   â””â”€â”€ main.ipynb
    â”œâ”€â”€ 02_Sequential_Workflows
    â”‚   â”œâ”€â”€ BMICalculator
    â”‚   â”‚   â””â”€â”€ main.ipynb
    â”‚   â””â”€â”€ SimpleLLM
    â”‚       â””â”€â”€ main.ipynb
    â”œâ”€â”€ 03_Parallel_Workflow
    â”‚   â”œâ”€â”€ BatsmanPerformance
    â”‚   â”‚   â””â”€â”€ main.ipynb
    â”‚   â””â”€â”€ UPSCEssay
    â”‚       â”œâ”€â”€ gemini.ipynb
    â”‚       â””â”€â”€ openai.ipynb
    â”œâ”€â”€ 04_Conditional_Workflows
    â”‚   â”œâ”€â”€ LLM_Based_Gemini.ipynb
    â”‚   â”œâ”€â”€ LLM_Based_OpenAI.ipynb
    â”‚   â””â”€â”€ Quadratic_Equation.ipynb
    â”œâ”€â”€ 05_Iteratice_Workflows
    â”‚   â”œâ”€â”€ X_Post_Generator_Gemini.ipynb
    â”‚   â””â”€â”€ X_Post_Generator_OpenAI.ipynb
    â”œâ”€â”€ 06_AdvancedChatbot
    â”‚   â”œâ”€â”€ app
    â”‚   â”‚   â”œâ”€â”€ __pycache__
    â”‚   â”‚   â”‚   â””â”€â”€ langgraph_backend.cpython-313.pyc
    â”‚   â”‚   â”œâ”€â”€ langgraph_backend.py
    â”‚   â”‚   â””â”€â”€ streamlit_frontend.py
    â”‚   â”œâ”€â”€ X_Post_Generator_Gemini.ipynb
    â”‚   â””â”€â”€ X_Post_Generator_OpenAI.ipynb
    â””â”€â”€ 07_Persistance
        â”œâ”€â”€ Persistence_Gemini.ipynb
        â””â”€â”€ Persistence_OpenAI.ipynb

15 directories, 19 files